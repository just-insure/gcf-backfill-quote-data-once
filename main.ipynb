{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GHjmYJpODXT7"
      },
      "outputs": [],
      "source": [
        "%autoawait asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "8zoMjBuoDc0t"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "from google.colab import data_table\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import logging\n",
        "from google.cloud import bigquery\n",
        "\n",
        "project = 'data-warehouse-267920' # Project ID inserted based on the query results selected to explore\n",
        "location = 'US' # Location inserted based on the query results selected to explore\n",
        "client = bigquery.Client(project=project, location=location)\n",
        "data_table.enable_dataframe_formatter()\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vfNI8quRDmhy"
      },
      "outputs": [],
      "source": [
        "query = \"\"\"\n",
        "SELECT\n",
        "  quote_id ,\n",
        "  user_id ,\n",
        "  zipcode zip_code,\n",
        "  case when substr(driver_classification, 1,1) = \"M\" then \"male\" else \"female\" end as gender ,\n",
        "  substr(driver_classification, 2,2) as age ,\n",
        "  vin ,\n",
        "  carYear ,\n",
        "  case when inflection_score is not null then inflection_score\n",
        "       when inflection_status = \"Unavailable\" and inflection_score is null then 400\n",
        "       when inflection_status = \"InsufficientData\" and inflection_score is null then 525\n",
        "       else null end as credit_score,\n",
        "  case when vio_1_code != \"0\" then 1 else 0 end as vio_1,\n",
        "  case when vio_2_code != \"0\" then 1 else 0 end as vio_2 ,\n",
        "  case when acc_1_code != \"0\" then 1 else 0 end as acc_1 ,\n",
        "  case when acc_2_code != \"0\" then 1 else 0 end as acc_2 ,\n",
        "  \"{bi}\" as bi,\n",
        "  \"{pd}\" as pd ,\n",
        "  \"{comp}\" as comp,\n",
        "  \"{coll}\" as coll ,\n",
        "  \"{marital_status}\" as marital_status,\n",
        "  \"{days_lapsed}\" as days_lapsed\n",
        "FROM `data-warehouse-267920.pricing_hub.elasticity_quotes`\n",
        "where inflection_status is not null and quote_created_at>= '2024-05-01' and quote_id not in (select quote_id from `price_comparison.competitor_prices_by_quote`)\n",
        "qualify row_number() over (partition by user_id  order by quote_created_at desc) = 1\n",
        "limit 20\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_V9YayI5ERgd"
      },
      "outputs": [],
      "source": [
        "async def run_main():\n",
        "    client = bigquery.Client(\"data-warehouse-267920\")\n",
        "    # query_job = client.query(query)\n",
        "    # query_job = client.query(query.format(bi=\"25/50\", pd=\"15000\", comp=\"500\", coll=\"500\", marital_status=\"single\", days_lapsed=0 ))\n",
        "    # df = query_job.to_dataframe()\n",
        "\n",
        "    # url = \"http://127.0.0.1:8000/compare\"\n",
        "    url = \"https://comparator-stg-axjyerdcyq-uc.a.run.app/compare\"\n",
        "\n",
        "    difference_list = []\n",
        "    exception_list = []\n",
        "    responses = []\n",
        "\n",
        "    BI = \"25/50\"\n",
        "    PD = \"15000\"\n",
        "    CP_CL = [('500','500'), ('None', 'None')]\n",
        "    MS = ['single', 'married']\n",
        "    DAYS_LAPSED = [0]\n",
        "\n",
        "    # calling the api\n",
        "    async def fetch_comparison(session, body, url, row_index, user_id):\n",
        "        try:\n",
        "            async with session.post(url, json=body, timeout=360) as response:\n",
        "                try:\n",
        "                    response_json = await response.json()\n",
        "                    response_json['index'] = row_index\n",
        "                    # print(f'{user_id},{response_json},{body}')\n",
        "                    response_json['user_id'] = user_id\n",
        "                    responses.append(response_json)\n",
        "                except TimeoutError as e:\n",
        "                    exception_list.append((row_index, e))\n",
        "                    # logger.error(f\"Error for index {row_index}: {e}\")\n",
        "                except Exception as e:\n",
        "                    try:\n",
        "                        async with session.post(url, json=body, timeout=360) as response_2:\n",
        "                            response_text = await response_2.text()\n",
        "                    except TimeoutError as e:\n",
        "                        exception_list.append((row_index, e))\n",
        "                    except Exception as e:\n",
        "                        exception_list.append((row_index, e))\n",
        "        except TimeoutError as e:\n",
        "            exception_list.append((row_index, e))\n",
        "            # logger.error(f\"Error for index {row_index}: {e}\")\n",
        "        except Exception as e:\n",
        "            exception_list.append((row_index, e))\n",
        "\n",
        "    # modifying data to fit api requirements\n",
        "    async def run_sample():\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            tasks = []\n",
        "            DF = pd.DataFrame()\n",
        "\n",
        "            for cp, cl in CP_CL:\n",
        "                for ms in MS:\n",
        "                    for days in DAYS_LAPSED:\n",
        "                        competitor_data = pd.DataFrame(columns=[\"quote_id\", \"bi_limits\", \"pd_limits\", \"comp_deductible\", \"coll_deductible\", \"days_lapsed\", \"marital_status\", \"carrier\", \"estimate\"])\n",
        "\n",
        "                        query_job = client.query(query.format(bi=BI, pd=PD, comp=cp, coll=cl, marital_status=ms, days_lapsed=days))\n",
        "                        df = query_job.to_dataframe()\n",
        "                        DF = pd.concat([df,DF])\n",
        "\n",
        "                        for row in df.iterrows():\n",
        "                            row = row[1]\n",
        "                            # partial vin from vin with wildcard for check (1gykpdrs.r)\n",
        "                            partial_vin = row[\"vin\"][:8].upper() + '.' + row[\"vin\"][9].upper()\n",
        "\n",
        "                            # insurance_score\n",
        "                            # 800\n",
        "                            # 525\n",
        "                            # 675\n",
        "                            # 400\n",
        "\n",
        "                            if row['credit_score'] >= 800:\n",
        "                                row['credit_score'] = 800\n",
        "                            elif row['credit_score'] >= 675:\n",
        "                                row['credit_score'] = 675\n",
        "                            elif row['credit_score'] >= 525:\n",
        "                                row['credit_score'] = 525\n",
        "                            else:\n",
        "                                row['credit_score'] = 400\n",
        "\n",
        "                            acv = np.minimum(2, row['vio_1'] + row['vio_2'] + row['acc_1'] + row['acc_2'])\n",
        "\n",
        "                            payload = {\n",
        "                                \"state\": \"AZ\",\n",
        "                                \"age\": row[\"age\"],\n",
        "                                \"gender\": row[\"gender\"].lower(),\n",
        "                                \"acv\": str(acv),\n",
        "                                \"zip\": str(row[\"zip_code\"]),\n",
        "                                \"insurance_score\": str(row[\"credit_score\"]),\n",
        "                                \"pd_limit\": str(PD),\n",
        "                                \"bi_limit\": str(BI),\n",
        "                                \"comp_deductible\": str(cp),\n",
        "                                \"coll_deductible\": str(cl),\n",
        "                                \"marital_status\": str(ms),\n",
        "                                \"days_lapsed\": str(days),\n",
        "                                \"vehicle\": {\n",
        "                                    \"partial_vin\": partial_vin\n",
        "                                }\n",
        "                            }\n",
        "                            tasks.append(fetch_comparison(session, payload, url, row.name, row['user_id']))\n",
        "                print(payload)\n",
        "            await asyncio.gather(*tasks)\n",
        "            return DF\n",
        "    DF = await run_sample()\n",
        "\n",
        "    # appending new api data to base data and recording any errors\n",
        "    # difference_list = pd.DataFrame([ {'index': r['index'], **rates} for r in responses for rates in r.get('rates'] ])\n",
        "    competitor_prices_list = []\n",
        "    errors = []\n",
        "\n",
        "    print(\"Number of Responses: \", len(responses))\n",
        "\n",
        "    print(f\"Number of Users that encountered error in request:  {len(exception_list)}\")\n",
        "    from collections import Counter\n",
        "\n",
        "    # Count exceptions by type\n",
        "    exceptions_count = Counter(type(exc[1]).__name__ for exc in exception_list)\n",
        "\n",
        "    # exceptions_count\n",
        "    print(exceptions_count)\n",
        "\n",
        "    for r in responses:\n",
        "        try:\n",
        "            for rates in r['rates']:\n",
        "                rates['index'] = r['index']\n",
        "                rates['upper_rate'] = rates['daily_rate']['upper_rate']\n",
        "                rates['lower_rate'] = rates['daily_rate']['lower_rate']\n",
        "                rates['rate'] = rates['daily_rate']['rate']\n",
        "                competitor_prices_list.append(rates)\n",
        "        except KeyError as e:\n",
        "            # Something Wrong With Data Validation in Comparison API\n",
        "            errors.append(\n",
        "                {'msg': r['detail'][0]['msg']}\n",
        "            )\n",
        "            continue\n",
        "\n",
        "    # putting new data and error data into dataframes\n",
        "\n",
        "    competitor_prices_list = pd.DataFrame(competitor_prices_list)\n",
        "    # print(competitor_prices_list)\n",
        "    df_errors = pd.DataFrame(errors)\n",
        "\n",
        "    competitor_prices_list.set_index('index', inplace=True)\n",
        "\n",
        "    competitor_prices = competitor_prices_list[['carrier', 'rate', 'upper_rate', 'lower_rate']].rename(\n",
        "        columns={'rate': 'estimate'})\n",
        "    competitor_prices = competitor_prices.join(DF)\n",
        "\n",
        "    job_config = bigquery.LoadJobConfig(\n",
        "        autodetect=True,\n",
        "        write_disposition=\"WRITE_APPEND\",\n",
        "        create_disposition=\"CREATE_IF_NEEDED\",\n",
        "        schema_update_options=\"ALLOW_FIELD_ADDITION\",\n",
        "    )\n",
        "\n",
        "    # TODO: Change the table id to the correct one\n",
        "    TABLE_ID = \"price_comparison.competitor_prices_by_quote\"\n",
        "\n",
        "    client = bigquery.Client(\"data-warehouse-267920\")\n",
        "    job = client.load_table_from_dataframe(\n",
        "        competitor_prices,\n",
        "        destination=TABLE_ID,\n",
        "        job_config=job_config\n",
        "    )\n",
        "\n",
        "    job.result()\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def main(request):\n",
        "    asyncio.run(run_main())\n",
        "    return \"200 OK\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRO1kqgEEvhC",
        "outputId": "d96f8fe8-a47d-4a17-b2e2-19df2c56ac51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'state': 'AZ', 'age': '87', 'gender': 'male', 'acv': '0', 'zip': '85225', 'insurance_score': '525', 'pd_limit': '15000', 'bi_limit': '25/50', 'comp_deductible': '500', 'coll_deductible': '500', 'marital_status': 'married', 'days_lapsed': '0', 'vehicle': {'partial_vin': 'JTDKDTB3.D'}}\n",
            "{'state': 'AZ', 'age': '22', 'gender': 'female', 'acv': '0', 'zip': '85201', 'insurance_score': '525', 'pd_limit': '15000', 'bi_limit': '25/50', 'comp_deductible': 'None', 'coll_deductible': 'None', 'marital_status': 'married', 'days_lapsed': '0', 'vehicle': {'partial_vin': '3N1CN7AP.H'}}\n",
            "Number of Responses:  80\n",
            "Number of Users that encountered error in request:  0\n",
            "Counter()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "await run_main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}